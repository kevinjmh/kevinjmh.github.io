
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>RAG CheatSheet - Manhua</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Obsidian,"> 
    <meta name="description" content="Personal site,langchain+ollama
本地文档常用模型：

SBert

ollama加载模型在线[src] https://ollama.com/libraryollama run gemma:2b
,"> 
    <meta name="author" content="Manhua"> 
    <link rel="alternative" href="atom.xml" title="Manhua" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">

    
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">

    
<link rel="stylesheet" href="/css/obsidian.css">

    
<link rel="stylesheet" href="/css/ball-atom.min.css">

    
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

    
<meta name="generator" content="Hexo 7.3.0"></head>


<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">Manhua</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="/img/favicon.png" alt="" data-url="http://kevinjmh.github.io">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">RAG CheatSheet</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url('/img/cover.jpg') ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/CheatSheet"><b>「
                    </b>CHEATSHEET<b> 」</b></a>
                
                March 19, 2024
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/2024/03/19/CheatSheet/ai/RAG/" title="RAG CheatSheet" class="">RAG CheatSheet</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>Words count</i>
                    27k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>Reading time</i>
                    25 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>Read count</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list" itemprop="keywords"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Langchain/" rel="tag">Langchain</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Ollama/" rel="tag">Ollama</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/RAG/" rel="tag">RAG</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <p>langchain+ollama</p>
<p>本地文档常用模型：</p>
<ul>
<li>SBert</li>
</ul>
<h1 id="ollama加载模型"><a href="#ollama加载模型" class="headerlink" title="ollama加载模型"></a>ollama加载模型</h1><h2 id="在线"><a href="#在线" class="headerlink" title="在线"></a>在线</h2><p>[src] <a target="_blank" rel="noopener" href="https://ollama.com/library">https://ollama.com/library</a><br><code>ollama run gemma:2b</code></p>
<h2 id="离线"><a href="#离线" class="headerlink" title="离线"></a>离线</h2><h4 id="1、创建模型配置文件"><a href="#1、创建模型配置文件" class="headerlink" title="1、创建模型配置文件"></a>1、创建模型配置文件</h4><p>创建模型配置文件，比如: <code>Modelfile</code> 这个文件名，文件内容指定需要加载的具体模型文件如下：</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM ./Meta-Llama-3-8B-Instruct-Q6_K.gguf</span><br></pre></td></tr></table></figure>

<h4 id="2、构建对应的Ollama模型"><a href="#2、构建对应的Ollama模型" class="headerlink" title="2、构建对应的Ollama模型"></a>2、构建对应的Ollama模型</h4><p>我们使用以下命令构建 Ollama 模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama create lm3 -f ./Modelfile</span><br></pre></td></tr></table></figure>

<p>其中 <code>lm3</code> 是我们准备在Ollama中使用该模型的别名。</p>
<p>这个命令的参数解释如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama create choose-a-model-name -f &lt;location of the file e.g. ./Modelfile&gt;</span><br></pre></td></tr></table></figure>

<h4 id="3、使用这个模型"><a href="#3、使用这个模型" class="headerlink" title="3、使用这个模型"></a>3、使用这个模型</h4><p>现在我们就可以使用了，由于是无内容审核的模型，我们可以发挥自己的想象：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run lm3 <span class="string">&quot;请写一个幽默笑话&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="langchain"><a href="#langchain" class="headerlink" title="langchain"></a>langchain</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain</span><br><span class="line">pip install langchain_community</span><br><span class="line">pip install langchain-chroma</span><br><span class="line">pip show langchain</span><br><span class="line"></span><br><span class="line"><span class="comment">#!/usr/bin/env python  </span></span><br><span class="line"><span class="comment"># coding=utf-8  </span></span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line">  </span><br><span class="line">documents = [  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;Dogs are great companions, known for their loyalty and friendliness.&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;mammal-pets-doc&quot;</span>&#125;,  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;Cats are independent pets that often enjoy their own space.&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;mammal-pets-doc&quot;</span>&#125;,  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;Goldfish are popular pets for beginners, requiring relatively simple care.&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;fish-pets-doc&quot;</span>&#125;,  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;Parrots are intelligent birds capable of mimicking human speech.&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;bird-pets-doc&quot;</span>&#125;,  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;Rabbits are social animals that need plenty of space to hop around.&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;mammal-pets-doc&quot;</span>&#125;,  </span><br><span class="line">    ),  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用文档创建向量数据库  </span></span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma  </span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> OllamaEmbeddings  </span><br><span class="line">oembed = OllamaEmbeddings(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;nomic-embed-text&quot;</span>)  </span><br><span class="line">vectorstore = Chroma.from_documents(documents, embedding=oembed)  </span><br><span class="line"><span class="comment"># vectorstore.similarity_search(&quot;cat&quot;)  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 测试查询文档  </span></span><br><span class="line"><span class="comment"># from langchain_core.runnables import RunnableLambda  </span></span><br><span class="line"><span class="comment"># docs = vectorstore.similarity_search(question)  </span></span><br><span class="line"><span class="comment"># retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result  </span></span><br><span class="line"><span class="comment"># retriever.batch([&quot;cat&quot;, &quot;shark&quot;])  </span></span><br><span class="line">  </span><br><span class="line">retriever = vectorstore.as_retriever(  </span><br><span class="line">    search_type=<span class="string">&quot;similarity&quot;</span>,  </span><br><span class="line">    search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">1</span>&#125;,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 检索问答链  </span></span><br><span class="line"><span class="comment"># 先基于问题的嵌入找到最相关的文档块，然后将这些文档块作为上下文，结合问题一起提交给ollama模型，以获取更加准确的答案  </span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate  </span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> RunnablePassthrough  </span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama  </span><br><span class="line">message = <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">Answer this question using the provided context only.  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">&#123;question&#125;  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">Context:  </span></span><br><span class="line"><span class="string">&#123;context&#125;  </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line">prompt = ChatPromptTemplate.from_messages([(<span class="string">&quot;human&quot;</span>, message)])  </span><br><span class="line">llm = Ollama(model=<span class="string">&quot;lm3&quot;</span>)  </span><br><span class="line">rag_chain = &#123;<span class="string">&quot;context&quot;</span>: retriever, <span class="string">&quot;question&quot;</span>: RunnablePassthrough()&#125; | prompt | llm  </span><br><span class="line">response = rag_chain.invoke(<span class="string">&quot;tell me about cats&quot;</span>)</span><br></pre></td></tr></table></figure>


<p>LangChain中的基本Embedding类公开两种方法：</p>
<ul>
<li><code>embed_documents</code>：适用于多个文档</li>
<li><code>embed_query</code>：适用于单个文档</li>
</ul>
<h2 id="load-document"><a href="#load-document" class="headerlink" title="load document"></a>load document</h2><h3 id="csv"><a href="#csv" class="headerlink" title="csv"></a>csv</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from langchain_community.document_loaders.csv_loader import CSVLoader</span><br><span class="line"></span><br><span class="line">file_path = (</span><br><span class="line">    &quot;../../../docs/integrations/document_loaders/example_data/mlb_teams_2012.csv&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">loader = CSVLoader(file_path=file_path)</span><br><span class="line">data = loader.load()</span><br><span class="line"></span><br><span class="line">for record in data[:2]:</span><br><span class="line">    print(record)</span><br></pre></td></tr></table></figure>

<h3 id="load-html"><a href="#load-html" class="headerlink" title="load html"></a>load html</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pip install bs4 # 处理Web文档加载</span><br><span class="line"></span><br><span class="line"># 使用Loader加载文档《奥德赛》  </span><br><span class="line">from langchain_community.document_loaders import WebBaseLoader  </span><br><span class="line">odyssey_url = &quot;https://www.gutenberg.org/files/1727/1727-h/1727-h.htm&quot;  </span><br><span class="line">loader = WebBaseLoader(odyssey_url)  </span><br><span class="line">data = loader.load()  </span><br><span class="line">  </span><br><span class="line"># 分割文档Document  </span><br><span class="line">from langchain_text_splitters import RecursiveCharacterTextSplitter  </span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)  </span><br><span class="line">all_splits = text_splitter.split_documents(data)</span><br></pre></td></tr></table></figure>

<h3 id="load-pdf-pymupdf"><a href="#load-pdf-pymupdf" class="headerlink" title="load pdf - pymupdf"></a>load pdf - pymupdf</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> PyMuPDFLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will load the PDF file</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_pdf_data</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="comment"># Creating a PyMuPDFLoader object with file_path</span></span><br><span class="line">    loader = PyMuPDFLoader(file_path=file_path)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># loading the PDF file</span></span><br><span class="line">    docs = loader.load()</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># returning the loaded document</span></span><br><span class="line">    <span class="keyword">return</span> docs</span><br><span class="line"></span><br><span class="line"><span class="comment"># Responsible for splitting the documents into several chunks</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_docs</span>(<span class="params">documents, chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">20</span></span>):</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Initializing the RecursiveCharacterTextSplitter with</span></span><br><span class="line">    <span class="comment"># chunk_size and chunk_overlap</span></span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        chunk_size=chunk_size,</span><br><span class="line">        chunk_overlap=chunk_overlap</span><br><span class="line">    )</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Splitting the documents into chunks</span></span><br><span class="line">    chunks = text_splitter.split_documents(documents=documents)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># returning the document chunks</span></span><br><span class="line">    <span class="keyword">return</span> chunks</span><br><span class="line"></span><br><span class="line"><span class="comment"># function for loading the embedding model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_embedding_model</span>(<span class="params">model_path, normalize_embedding=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">return</span> OllamaEmbeddings(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;nomic-embed-text&quot;</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># Function for creating embeddings using FAISS</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_embeddings</span>(<span class="params">chunks, embedding_model, storing_path=<span class="string">&quot;vectorstore&quot;</span></span>):</span><br><span class="line">    <span class="comment"># Creating the embeddings using FAISS</span></span><br><span class="line">    vectorstore = Chroma.from_documents(chunks, embedding_model)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Saving the model in current directory</span></span><br><span class="line">    vectorstore.save_local(storing_path)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># returning the vectorstore</span></span><br><span class="line">    <span class="keyword">return</span> vectorstore</span><br><span class="line"></span><br><span class="line">prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">### System:</span></span><br><span class="line"><span class="string">You are an AI Assistant that follows instructions extreamly well. \</span></span><br><span class="line"><span class="string">Help as much as you can.</span></span><br><span class="line"><span class="string">### User:</span></span><br><span class="line"><span class="string">&#123;prompt&#125;</span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">### System:</span></span><br><span class="line"><span class="string">You are an respectful and honest assistant. You have to answer the user&#x27;s \</span></span><br><span class="line"><span class="string">questions using only the context provided to you. If you don&#x27;t know the answer, \</span></span><br><span class="line"><span class="string">just say you don&#x27;t know. Don&#x27;t try to make up an answer.</span></span><br><span class="line"><span class="string">### Context:</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">### User:</span></span><br><span class="line"><span class="string">&#123;question&#125;</span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating the chain for Question Answering</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_qa_chain</span>(<span class="params">retriever, llm, prompt</span>):</span><br><span class="line">    <span class="keyword">return</span> RetrievalQA.from_chain_type(</span><br><span class="line">        llm=llm,</span><br><span class="line">        retriever=retriever, <span class="comment"># here we are using the vectorstore as a retriever</span></span><br><span class="line">        chain_type=<span class="string">&quot;stuff&quot;</span>,</span><br><span class="line">        return_source_documents=<span class="literal">True</span>, <span class="comment"># including source documents in output</span></span><br><span class="line">        chain_type_kwargs=&#123;<span class="string">&#x27;prompt&#x27;</span>: prompt&#125; <span class="comment"># customizing the prompt</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prettifying the response</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_response</span>(<span class="params">query, chain</span>):</span><br><span class="line">    <span class="comment"># Getting response from chain</span></span><br><span class="line">    response = chain(&#123;<span class="string">&#x27;query&#x27;</span>: query&#125;)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Wrapping the text for better output in Jupyter Notebook</span></span><br><span class="line">    wrapped_text = textwrap.fill(response[<span class="string">&#x27;result&#x27;</span>], width=<span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span>(wrapped_text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lang_funcs <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> Ollama</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loading orca-mini from Ollama</span></span><br><span class="line">llm = Ollama(model=<span class="string">&quot;orca-mini&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Loading the Embedding Model</span></span><br><span class="line">embed = load_embedding_model(model_path=<span class="string">&quot;all-MiniLM-L6-v2&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loading and splitting the documents</span></span><br><span class="line">docs = load_pdf_data(file_path=<span class="string">&quot;data/ml_book.pdf&quot;</span>)</span><br><span class="line">documents = split_docs(documents=docs)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># creating vectorstore</span></span><br><span class="line">vectorstore = create_embeddings(documents, embed)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># converting vectorstore to a retriever</span></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating the prompt from the template which we created before</span></span><br><span class="line">prompt = PromptTemplate.from_template(template)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Creating the chain</span></span><br><span class="line">chain = load_qa_chain(retriever, llm, prompt)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;get_response(<span class="string">&quot;What is random forest?&quot;</span>, chain)</span><br></pre></td></tr></table></figure>

<h1 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h1><h2 id="C-S"><a href="#C-S" class="headerlink" title="C&#x2F;S"></a>C&#x2F;S</h2><p>AnythingLLM<br>GPT4All</p>
<h2 id="B-S"><a href="#B-S" class="headerlink" title="B&#x2F;S"></a>B&#x2F;S</h2><p><a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui">open-webui&#x2F;open-webui: User-friendly WebUI for LLMs (Formerly Ollama WebUI) (github.com)</a></p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
                
                <li title='0' data-url='/statics/chengdu.mp3'></li>
                
                    
            </ul>
            
                        
            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="https://s2.ax1x.com/2019/09/19/nLtSiD.png" height=300 width=300></img>
                    <p>Manhua</p>
                    <span>Think like an artist, develop like an artisan</span>
                    <dl>
                        
                            
                            
                            
                        
                        
                    </dl>
                </div>
                <ul>
                    <li><a href="/">101 <p>Articles</p></a></li>
                    <li><a href="/categories">10 <p>Categories</p></a></li>
                    <li><a href="/tags">29 <p>Tags</p></a></li>
                </ul>
            </div>
            
            
            
            <div class="box sticky animated fadeInRight faster">
                <div id="toc" class="subbox">
                    <h4>Contents</h4>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ollama%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">ollama加载模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E7%BA%BF"><span class="toc-number">1.1.</span> <span class="toc-text">在线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A6%BB%E7%BA%BF"><span class="toc-number">1.2.</span> <span class="toc-text">离线</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#langchain"><span class="toc-number">2.</span> <span class="toc-text">langchain</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#load-document"><span class="toc-number">2.1.</span> <span class="toc-text">load document</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#csv"><span class="toc-number">2.1.1.</span> <span class="toc-text">csv</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#load-html"><span class="toc-number">2.1.2.</span> <span class="toc-text">load html</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#load-pdf-pymupdf"><span class="toc-number">2.1.3.</span> <span class="toc-text">load pdf - pymupdf</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E7%AB%AF"><span class="toc-number">3.</span> <span class="toc-text">前端</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#C-S"><span class="toc-number">3.1.</span> <span class="toc-text">C&#x2F;S</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#B-S"><span class="toc-number">3.2.</span> <span class="toc-text">B&#x2F;S</span></a></li></ol></li></ol>
                </div>
            </div>
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2025
        <span class="gradient-text">
            Manhua
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.9.4" target="_blank" rel="noopener">v1.4.9.4</a></small>
        
        
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>


 
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
 
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
 
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
 
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>


<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>
 
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>
   
<script src="/js/busuanzi.min.js"></script>

<script>
  $(document).ready(function () {
    if ($('span[id^="busuanzi_"]').length) {
      initialBusuanzi();
    }
  });
</script>
 
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">


<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
  

<script>
  function initialTyped() {
    var typedTextEl = $('.typed-text');
    if (typedTextEl && typedTextEl.length > 0) {
      var typed = new Typed('.typed-text', {
        strings: ['Think like an artist, develop like an artisan', '艺术家思维去思考问题，工匠创造精神去开发'],
        typeSpeed: 90,
        loop: true,
        loopCount: Infinity,
        backSpeed: 20,
      });
    }
  }

  if ($('.article-header') && $('.article-header').length) {
    $(document).ready(function () {
      initialTyped();
    });
  }
</script>







</html>
